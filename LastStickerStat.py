from bs4 import BeautifulSoup
import datetime
import json
import os
import pandas as pd
import re
import requests
import sys
from tqdm import tqdm
from tqdm.contrib.telegram import tqdm as tq


class LastStickerStat(object):

    def __set_consts(self):
        # ÐÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ Ð´Ð»Ñ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾Ð¹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ñ‡ÐµÑ€ÐµÐ· Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼ Ð±Ð¾Ñ‚ Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ/Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        with open("config.json", "r") as f:
            config = json.load(f)
        self.MAIN_URL = config["MAIN_URL"]
        self.FIRST_AUCTION = config["FIRST_AUCTION"]
        self.FIRST_NEW_AUCTION = config["FIRST_NEW_AUCTION"]
        self.COL_NAMES = config["COL_NAMES"]
        MONTH_NAMES = config["MONTH_NAMES"]
        self.MONTH_TO_NUM = dict((m, str(n)) for (n, m) in enumerate(MONTH_NAMES, start=1))
        self.DECODE_SBJ = config["DECODE_SBJ"]
        self.DECODE_THEME = config["DECODE_THEME"]
        self.DECODE_LOT_TYPE = config["DECODE_LOT_TYPE"]
        self.DECODE_SORT_BY = config["DECODE_SORT_BY"]
        self.DECODE_STATUS = config["DECODE_STATUS"]

    # Ð›Ð¸Ð±Ð¾ ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ Ð±Ð°Ð·Ñƒ Ñ Ñ‡Ð¸ÑÑ‚Ð¾Ð³Ð¾ Ð»Ð¸ÑÑ‚Ð°, Ð»Ð¸Ð±Ð¾ ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÑƒÐ¶Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ
    def __init__(self, file_name, token=""):
        self.__set_consts()
        self.dir_path = "{}".format(file_name)
        self.csv_path = "{}/{}.csv".format(self.dir_path, file_name)
        self.upper_csv_path = "{}/upper_{}.csv".format(self.dir_path, file_name)
        self.json_path = "{}/{}.json".format(self.dir_path, file_name)
        self.csv_batch = 500  # Ð Ð°Ð· Ð²Ð¾ ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ† Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ csv
        self.upd_allowed = True  # False, ÐµÑÐ»Ð¸ update() ÑƒÐ¶Ðµ Ð²Ñ‹Ð·Ð²Ð°Ð»Ð¸
        self.token = token
        if not os.path.isdir(self.dir_path):
            os.mkdir(self.dir_path)
            # Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ñ ÑÐ°Ð¼Ð¾Ð³Ð¾ Ð½Ð°Ñ‡Ð°Ð»Ð°
            self.__parse_all()
        else:
            # Ð¡Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ð½Ð¸Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ¹ Ð±Ð°Ð·Ñ‹ Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ Ð½ÐµÐ¹
            self.df = pd.read_csv(self.csv_path, sep=";", low_memory=False)
            self.df_upper = pd.read_csv(self.upper_csv_path, sep=";", low_memory=False)
            with open(self.json_path, "r") as f:
                self.info = json.load(f)

    # ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ñ‹Ð¹ Ð»Ð¾Ñ‚ Ð½Ð° ÑÐ°Ð¹Ñ‚Ðµ Ð½Ð° Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ Ð²Ñ‹Ð·Ð¾Ð²Ð° ÑÑ‚Ð¾Ð¹ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸. ÐšÐ°Ðº Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð¾ ÑÑ‚Ð¾ Ð¿ÐµÑ€Ð²Ð°Ñ ÑÑÑ‹Ð»ÐºÐ°
    # Ð½Ð¸Ð¶Ðµ Ð½Ð°Ð´Ð¿Ð¸ÑÐ¸ "Ð’ÑÐµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ" Ð½Ð° ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ðµ https://www.laststicker.ru/auction/
    @staticmethod
    def last_lot_url_id_now():
        response = requests.get("https://www.laststicker.ru/auction/")
        soup = BeautifulSoup(response.content, "html.parser")
        return int(soup.find_all("h2")[-2].next_sibling.a["href"][13:-1])

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ„Ð°Ð¹Ð» csv Ñ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð±Ð°Ð·Ð¾Ð¹
    def __write_empty_csv(self):
        pd.DataFrame(columns=self.COL_NAMES).to_csv(self.csv_path, sep=";", header=self.COL_NAMES, index=False)
        pd.DataFrame(columns=["title", "collection"]).to_csv(self.upper_csv_path, sep=";",
                                                             header=["title", "collection"], index=False)

    # ÐŸÐ°Ñ€ÑÐ¸Ð¼ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ Ñ ÑÐ°Ð¼Ð¾Ð³Ð¾ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ Ð»Ð¾Ñ‚Ð°, Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾Ð³Ð¾ Ð½Ð° ÑÐ°Ð¹Ñ‚Ðµ, Ð¸ Ð´Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾
    def __parse_all(self):
        self.info = {"unparsed_pages": [], "lots_amount": 0}
        self.df = pd.DataFrame(columns=self.COL_NAMES)
        self.df_upper = pd.DataFrame(columns=["title", "collection"])
        self.__write_empty_csv()

        # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÑ‚Ð°Ñ€Ð¾Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð½Ñ‹Ñ… Ð°ÑƒÐºÑ†Ð¸Ð¾Ð½Ð¾Ð²
        self.__parse_old_to_csv()

        self.info["last_lot_url_id"] = self.last_lot_url_id_now()

        now = datetime.datetime.now()
        self.info["last_lot_parse_date"] = "{}:{} {}.{}.{}".format(now.hour, now.minute, now.day, now.month, now.year)

        # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð½Ð¾Ð²Ð¾Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð½Ñ‹Ñ… Ð°ÑƒÐºÑ†Ð¸Ð¾Ð½Ð¾Ð²
        self.__parse_to_csv(self.FIRST_NEW_AUCTION, self.info["last_lot_url_id"], False)

    # ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ ÑÑ‚Ð°Ñ€Ð¾Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð½Ñ‹Ñ… Ð»Ð¾Ñ‚Ð¾Ð²
    def __parse_old_to_csv(self):

        passed_pages = 0
        df = pd.DataFrame(columns=self.COL_NAMES)
        df_upper = pd.DataFrame(columns=["title", "collection"])

        for i in tqdm(range(self.FIRST_AUCTION, self.FIRST_NEW_AUCTION)):
            try:
                page_num = i
                url = self.MAIN_URL + "/auction/post{}/".format(page_num)
                response = requests.get(url)

                if response.status_code == 200:

                    # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð²ÑÐµ Ñ„Ð¾Ñ€ÑƒÐ¼Ð½Ñ‹Ðµ Ð¸ Ð¸Ð¶Ðµ Ñ Ð½Ð¸Ð¼Ð¸ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹. ÐÐ°Ñ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑƒÑŽÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
                    soup = BeautifulSoup(response.content, "html.parser")
                    if soup.find("div", id="nav").contents[2].text != "ÐÑƒÐºÑ†Ð¸Ð¾Ð½":
                        raise

                    # Ð•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ description, Ñ‡Ð°Ñ‰Ðµ Ð²ÑÐµÐ³Ð¾ Ñ‚Ð°Ð¼ Ð½Ð°Ð¿Ð¸ÑÐ°Ð½Ð¾, ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹ Ð¸Ð»Ð¸ Ð½Ð°ÐºÐ»ÐµÐµÑ‡Ð½Ñ‹Ð¹ ÑÑ‚Ð¾ Ð»Ð¾Ñ‚
                    tag_description = soup.find("meta", {"name": re.compile("description")})
                    header = "" if tag_description == None else tag_description["content"]

                    # Ð’Ñ‹Ñ‚Ð°ÑÐºÐ¸Ð²Ð°ÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð¸ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑŽ Ð»Ð¾Ñ‚Ð° (Ð¥Ð¾ÐºÐºÐµÐ¹Ð½Ñ‹Ðµ ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸, ÐœÑƒÐ»ÑŒÑ‚Ñ„Ð¸Ð»ÑŒÐ¼Ñ‹ Ð¸ ÐºÐ¸Ð½Ð¾,
                    # Ð”Ñ€ÑƒÐ³Ð¸Ðµ Ð²Ð¸Ð´Ñ‹ ÑÐ¿Ð¾Ñ€Ñ‚Ð° Ð¸Ñ‚Ð´)
                    title = soup.h1.text
                    theme = soup.find("div", id="nav").contents[-1].text

                    # Ð•ÑÐ»Ð¸ Ð¿Ð¾Ð¿Ð°Ð»Ð°ÑÑŒ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ Ð”Ñ€ÑƒÐ³Ð¸Ðµ Ð²Ð¸Ð´Ñ‹ ÑÐ¿Ð¾Ñ€Ñ‚Ð° Ð¸Ð»Ð¸ ÐœÑƒÐ»ÑŒÑ‚Ñ„Ð¸Ð»ÑŒÐ¼Ñ‹ Ð¸ ÐºÐ¸Ð½Ð¾, Ñ‚Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ñ‚Ð°Ðº Ð½Ðµ Ð¿Ð¾Ð¹Ð¼ÐµÑˆÑŒ,
                    # ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹ Ð¸Ð»Ð¸ Ð½Ð°ÐºÐ»ÐµÐµÑ‡Ð½Ñ‹Ð¹ ÑÑ‚Ð¾ Ð»Ð¾Ñ‚. ÐÐ°Ð´Ð¾ Ð¿Ð¾Ð´Ð³Ð»ÑÐ´Ñ‹Ð²Ð°Ñ‚ÑŒ Ð² description
                    if theme in ["Ð”Ñ€ÑƒÐ³Ð¸Ðµ Ð²Ð¸Ð´Ñ‹ ÑÐ¿Ð¾Ñ€Ñ‚Ð°", "ÐœÑƒÐ»ÑŒÑ‚Ñ„Ð¸Ð»ÑŒÐ¼Ñ‹ Ð¸ ÐºÐ¸Ð½Ð¾"] and header != "":
                        is_sticker = "Ð½Ð°ÐºÐ»ÐµÐµÐº" in header
                        is_card = "ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐµÐº" in header
                        is_undefined = not (is_sticker ^ is_card)
                    # Ð•ÑÐ»Ð¸ Ð¸ description Ð¿ÑƒÑÑ‚Ð¾Ð¹/ÐµÐ³Ð¾ Ð½ÐµÑ‚, Ñ‚Ð¾ Ð¼ÐµÑ‚Ð¾Ð´Ð°Ð¼Ð¸ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ð½Ðµ ÑƒÐ·Ð½Ð°Ñ‚ÑŒ, Ð½Ð°ÐºÐ»ÐµÐµÑ‡Ð½Ñ‹Ð¹ Ð¸Ð»Ð¸ ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹
                    # ÑÑ‚Ð¾ Ð»Ð¾Ñ‚. ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚ Ð»Ð¾Ñ‚Ð° ÐºÐ°Ðº ÐÐµÐ¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¾
                    elif theme in ["Ð”Ñ€ÑƒÐ³Ð¸Ðµ Ð²Ð¸Ð´Ñ‹ ÑÐ¿Ð¾Ñ€Ñ‚Ð°", "ÐœÑƒÐ»ÑŒÑ‚Ñ„Ð¸Ð»ÑŒÐ¼Ñ‹ Ð¸ ÐºÐ¸Ð½Ð¾"]:
                        is_undefined = True
                    # Ð•ÑÐ»Ð¸ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ (theme) Ð»Ð¾Ñ‚Ð° Ð½Ðµ Ð”Ñ€ÑƒÐ³Ð¸Ðµ Ð²Ð¸Ð´Ñ‹ ÑÐ¿Ð¾Ñ€Ñ‚Ð° Ð¸ Ð½Ðµ ÐœÑƒÐ»ÑŒÑ‚Ñ„Ð¸Ð»ÑŒÐ¼Ñ‹ Ð¸ ÐºÐ¸Ð½Ð¾, Ñ‚Ð¾Ð³Ð´Ð° Ð»ÐµÐ³ÐºÐ¾ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ð¼
                    # "Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚" Ð»Ð¾Ñ‚Ð° (ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸/Ð½Ð°ÐºÐ»ÐµÐ¹ÐºÐ¸/Ð´Ñ€ÑƒÐ³Ð¾Ðµ)
                    else:
                        is_undefined = False
                        cards = ["Ð¥Ð¾ÐºÐºÐµÐ¹Ð½Ñ‹Ðµ ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸", "Ð¤ÑƒÑ‚Ð±Ð¾Ð»ÑŒÐ½Ñ‹Ðµ ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸", "ÐŸÑ€Ð¾Ñ‡Ð¸Ðµ ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸", "ÐšÐšÐ˜"]
                        stickers = ["Ð¤ÑƒÑ‚Ð±Ð¾Ð»ÑŒÐ½Ñ‹Ðµ Ð½Ð°ÐºÐ»ÐµÐ¹ÐºÐ¸", "Ð¥Ð¾ÐºÐºÐµÐ¹Ð½Ñ‹Ðµ Ð½Ð°ÐºÐ»ÐµÐ¹ÐºÐ¸", "ÐŸÑ€Ð¾Ñ‡Ð¸Ðµ Ð½Ð°ÐºÐ»ÐµÐ¹ÐºÐ¸"]
                        is_sticker = theme in stickers
                        is_card = theme in cards
                    is_other = not is_undefined and not (is_sticker or is_card)
                    subject = "ÐÐµÐ¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¾" if is_undefined else "ÐšÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸" * is_card + \
                                                                  "ÐÐ°ÐºÐ»ÐµÐ¹ÐºÐ¸" * is_sticker + "Ð”Ñ€ÑƒÐ³Ð¾Ðµ" * is_other
                    # Ð’Ñ‹Ñ‚Ð°ÑÐºÐ¸Ð²Ð°ÐµÐ¼ url Ð¸ Ð½Ð¸Ðº Ð¿Ñ€Ð¾Ð´Ð°Ð²Ñ†Ð°
                    tag_seller = soup.find("div", "head_bg-l clearer").find_all("a", class_="")[1]
                    seller_url = self.MAIN_URL + tag_seller["href"]
                    seller_nickname = tag_seller.text

                    # Ð’Ñ‹Ñ‚Ð°ÑÐºÐ¸Ð²Ð°ÐµÐ¼ Ð»Ð¾ÐºÐ°Ñ†Ð¸ÑŽ Ð¿Ñ€Ð¾Ð´Ð°Ð²Ñ†Ð°
                    seller_location_city = soup.find("div", class_="forum_left").contents[-1]
                    seller_location_country, seller_location_district = None, None

                    # Ð’Ñ‹Ñ‚Ð°ÑÐºÐ¸Ð²Ð°ÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÐºÐ¾Ð»Ð»ÐµÑ†Ð¸Ð¸ Ð»Ð¾Ñ‚Ð°, ÐµÑÐ»Ð¸ ÑÑ‚Ð° Ð¸Ð½Ñ„-Ñ ÐµÑÑ‚ÑŒ
                    tag_album = soup.find_all("div", class_="album_item")
                    if tag_album != [] and tag_album[-1].h3 != None and tag_album[-1].h3.a != None:
                        collection = tag_album[-1].h3.a.text
                        url_collection = self.MAIN_URL + tag_album[-1].h3.a["href"]
                        if "/cards/" not in url_collection:
                            collection, url_collection = None, None
                    else:
                        collection, url_collection = None, None

                    # Ð’Ñ‹Ñ‚Ð°ÑÐºÐ¸Ð²Ð°ÐµÐ¼ Ð¸Ð½Ñ„-ÑŽ Ð¾ Ð´Ð°Ñ‚Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ/Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ñ Ð»Ð¾Ñ‚Ð°
                    date_start_txt = soup.find_all("div", class_="forum_left")[0].span.text
                    date_start = date_start_txt.split("\xa0")
                    date_start[1] = self.MONTH_TO_NUM[date_start[1]]
                    if len(date_start) == 3:
                        date_start.insert(2, str(datetime.datetime.now().year))
                    date_start_day = date_start[0]
                    date_start_month = date_start[1]
                    date_start_year = date_start[2]
                    date_start_time = date_start[3]

                    # Ð¡Ð»Ð¾Ð¶Ð½Ð¾ Ð²Ñ‹Ð¿Ð°Ñ€ÑÐ¸Ñ‚ÑŒ Ð´Ð°Ñ‚Ñƒ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ñ ÑÑ‚Ð°Ñ€Ð¾Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð½Ð¾Ð³Ð¾ Ð»Ð¾Ñ‚Ð°, Ð¿Ð¾ÑÑ‚Ð¾Ð¼Ñƒ Ð½Ðµ Ð±ÑƒÐ´ÐµÐ¼ Ð´Ð°Ð¶Ðµ Ð¿Ñ‹Ñ‚Ð°Ñ‚ÑŒÑÑ
                    date_end_day, date_end_month, date_end_year, date_end_time = None, None, None, None

                    # Ð’ÑÑŽ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ð² Ð°Ñ‚Ñ€Ð¸Ð±ÑƒÑ‚ Ð¾Ð±ÑŠÐµÐºÑ‚Ð° ÐºÐ»Ð°ÑÑÐ° df Ð¸ df_upper
                    dct = {"title": title, "url": url, "subject": subject, "theme": theme, "lot_type": "Ð¡Ñ‚Ð°Ñ€Ð¾Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð½Ñ‹Ð¹",
                           "status": "Ð—Ð°ÐºÑ€Ñ‹Ñ‚", "is_bet_made": None, "collection": collection,
                           "url_collection": url_collection, "date_start_day": date_start_day,
                           "date_start_month": date_start_month, "date_start_year": date_start_year,
                           "date_start_time": date_start_time, "seller_nickname": seller_nickname,
                           "seller_url": seller_url, "seller_location_city": seller_location_city,
                           "seller_location_district": seller_location_district,
                           "seller_location_country": seller_location_country, "initial_price": None,
                           "last_price": None, "last_price_author": None, "url_last_buyer": None,
                           "date_end_day": date_end_day, "date_end_month": date_end_month,
                           "date_end_year": date_end_year, "date_end_time": date_end_time}
                    df = df.append(dct, ignore_index=True)
                    collection_upper = None if collection == None else collection.upper()
                    df_upper = df_upper.append({"title": title.upper(), "collection": collection_upper},
                                               ignore_index=True)

                    self.df = self.df.append(dct, ignore_index=True)
                    self.df_upper = self.df_upper.append({"title": title.upper(), "collection": collection_upper},
                                                         ignore_index=True)

                    passed_pages += 1

                    # ÐšÐ°Ð¶Ð´Ñ‹Ðµ csv_batch ÑÑÑ‹Ð»Ð¾Ðº Ð¿Ð¾Ð´Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð»Ð¾Ñ‚Ð°Ñ… Ð² csv Ñ„Ð°Ð¹Ð»
                    if passed_pages % self.csv_batch == 0:
                        df.to_csv(self.csv_path, sep=";", mode="a", header=False, index=False)
                        df = pd.DataFrame(columns=self.COL_NAMES)
                        df_upper.to_csv(self.upper_csv_path, sep=";", mode="a", header=False, index=False)
                        df_upper = pd.DataFrame(columns=["title", "collection"])

            except Exception:
                self.info["unparsed_pages"].append(url)

        self.info["lots_amount"] += passed_pages

        # Ð”Ð¾Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ csv Ñ„Ð°Ð¹Ð» (Ñƒ Ð½Ð°Ñ Ð¼Ð¾Ð³ Ð¾ÑÑ‚Ð°Ñ‚ÑŒÑÑ Ð½Ðµ Ð·Ð°Ð¿Ð¸ÑÐ°Ð½Ð½Ñ‹Ð¹ ÐºÑƒÑÐ¾Ðº)
        df.to_csv(self.csv_path, sep=";", mode="a", header=False, index=False)
        df_upper.to_csv(self.upper_csv_path, sep=";", mode="a", header=False, index=False)

    # ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð½Ð¾Ð²Ð¾Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð½Ñ‹Ñ… Ð»Ð¾Ñ‚Ð¾Ð²
    def __parse_to_csv(self, first_page, last_page, json_written, chat_id=None):

        passed_pages = 0
        df = pd.DataFrame(columns=self.COL_NAMES)
        df_upper = pd.DataFrame(columns=["title", "collection"])

        rng = tqdm(range(first_page, last_page + 1)) if chat_id == None else tq(range(first_page, last_page + 1),
                                                                                token=self.token, chat_id=chat_id)

        for i in rng:
            try:
                page_num = i
                url = self.MAIN_URL + "/auction/post{}/".format(page_num)
                response = requests.get(url)

                if response.status_code == 200:

                    soup = BeautifulSoup(response.content, "html.parser")
                    if soup.find("div", id="nav").contents[2].text != "ÐÑƒÐºÑ†Ð¸Ð¾Ð½":
                        raise

                    tag_description = soup.find("meta", {"name": re.compile("description")})
                    header = "" if tag_description == None else tag_description["content"]

                    title = soup.h1.text
                    theme = soup.find("div", id="nav").contents[-1].text

                    if theme in ["Ð”Ñ€ÑƒÐ³Ð¸Ðµ Ð²Ð¸Ð´Ñ‹ ÑÐ¿Ð¾Ñ€Ñ‚Ð°", "ÐœÑƒÐ»ÑŒÑ‚Ñ„Ð¸Ð»ÑŒÐ¼Ñ‹ Ð¸ ÐºÐ¸Ð½Ð¾"] and header != "":
                        is_sticker = "Ð½Ð°ÐºÐ»ÐµÐµÐº" in header
                        is_card = "ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐµÐº" in header
                        is_undefined = not (is_sticker ^ is_card)
                    elif theme in ["Ð”Ñ€ÑƒÐ³Ð¸Ðµ Ð²Ð¸Ð´Ñ‹ ÑÐ¿Ð¾Ñ€Ñ‚Ð°", "ÐœÑƒÐ»ÑŒÑ‚Ñ„Ð¸Ð»ÑŒÐ¼Ñ‹ Ð¸ ÐºÐ¸Ð½Ð¾"]:
                        is_undefined = True
                    else:
                        is_undefined = False
                        cards = ["Ð¥Ð¾ÐºÐºÐµÐ¹Ð½Ñ‹Ðµ ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸", "Ð¤ÑƒÑ‚Ð±Ð¾Ð»ÑŒÐ½Ñ‹Ðµ ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸", "ÐŸÑ€Ð¾Ñ‡Ð¸Ðµ ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸", "ÐšÐšÐ˜"]
                        stickers = ["Ð¤ÑƒÑ‚Ð±Ð¾Ð»ÑŒÐ½Ñ‹Ðµ Ð½Ð°ÐºÐ»ÐµÐ¹ÐºÐ¸", "Ð¥Ð¾ÐºÐºÐµÐ¹Ð½Ñ‹Ðµ Ð½Ð°ÐºÐ»ÐµÐ¹ÐºÐ¸", "ÐŸÑ€Ð¾Ñ‡Ð¸Ðµ Ð½Ð°ÐºÐ»ÐµÐ¹ÐºÐ¸"]
                        is_sticker = theme in stickers
                        is_card = theme in cards
                    is_other = not is_undefined and not (is_sticker or is_card)
                    subject = "ÐÐµÐ¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¾" if is_undefined else "ÐšÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸" * is_card + \
                                                                  "ÐÐ°ÐºÐ»ÐµÐ¹ÐºÐ¸" * is_sticker + "Ð”Ñ€ÑƒÐ³Ð¾Ðµ" * is_other
                    # Ð’Ñ‹Ñ‚Ð°ÑÐºÐ¸Ð²Ð°ÐµÐ¼ Ð´Ð°Ñ‚Ñƒ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ñ Ð»Ð¾Ñ‚Ð°
                    tag_closed = soup.find("div", id=re.compile("auction_bid_countdown"))
                    is_closed = "Ð”Ð°Ñ‚Ð° Ð¸ Ð²Ñ€ÐµÐ¼Ñ Ð¾ÐºÐ¾Ð½Ñ‡Ð°Ð½Ð¸Ñ" in tag_closed.text

                    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼, Ð¿ÐµÑ€ÐµÐ´ Ð½Ð°Ð¼Ð¸ Ð°ÑƒÐºÑ†Ð¸Ð¾Ð½ Ð¸Ð»Ð¸ Ð¾Ð±ÑŠÑÐ²Ð»ÐµÐ½Ð¸Ðµ
                    tag_auction = soup.find("div", {"style": re.compile("float: left; width: 50%")})
                    # Ð¡Ñ‚Ð°Ð²Ð¾Ðº ÐµÑ‰Ðµ Ð½Ðµ Ð±Ñ‹Ð»Ð¾, ÐµÑÐ»Ð¸ Ð² ÑÑ‚Ð¾Ð¼ Ñ‚ÐµÐ³Ðµ ÐµÑÑ‚ÑŒ "ÐÐ°Ñ‡Ð°Ð»ÑŒÐ½Ð°Ñ ÑÑ‚Ð°Ð²ÐºÐ°"
                    no_bets = "ÐÐ°Ñ‡Ð°Ð»ÑŒÐ½Ð°Ñ ÑÑ‚Ð°Ð²ÐºÐ°" in tag_auction.text
                    # ÐÑƒÐºÑ†Ð¸Ð¾Ð½ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½ Ð¸ ÑÑ‚Ð°Ð²ÐºÐ° Ð±Ñ‹Ð»Ð° ÑÐ´ÐµÐ»Ð°Ð½Ð°, ÐµÑÐ»Ð¸ Ð² Ñ‚ÐµÐ³Ðµ ÐµÑÑ‚ÑŒ "ÐŸÐ¾Ð±ÐµÐ´Ð½Ð°Ñ ÑÑ‚Ð°Ð²ÐºÐ°"
                    smbd_won = "ÐŸÐ¾Ð±ÐµÐ´Ð½Ð°Ñ ÑÑ‚Ð°Ð²ÐºÐ°" in tag_auction.text
                    # ÐÑƒÐºÑ†Ð¸Ð¾Ð½ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚ Ð¸ ÑÑ‚Ð°Ð²ÐºÐ° Ð±Ñ‹Ð»Ð° ÑÐ´ÐµÐ»Ð°Ð½Ð°, ÐµÑÐ»Ð¸ Ð² Ñ‚ÐµÐ³Ðµ ÐµÑÑ‚ÑŒ "Ð¢ÐµÐºÑƒÑ‰Ð°Ñ ÑÑ‚Ð°Ð²ÐºÐ°"
                    is_bet_made = "Ð¢ÐµÐºÑƒÑ‰Ð°Ñ ÑÑ‚Ð°Ð²ÐºÐ°" in tag_auction.text

                    is_auction = no_bets or smbd_won or is_bet_made
                    is_bet_made = is_auction and not no_bets  # Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° (2)
                    is_offer = not is_auction
                    lot_type = "ÐÑƒÐºÑ†Ð¸Ð¾Ð½" * is_auction + "ÐžÐ±ÑŠÑÐ²Ð»ÐµÐ½Ð¸Ðµ" * is_offer

                    # Ð•ÑÐ»Ð¸ Ð°ÑƒÐºÑ†Ð¸Ð¾Ð½, Ñ‚Ð¾ ÐµÑÑ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ ÑÑ‚Ð°Ð²ÐºÐ°Ñ…. Ð”Ð¾ÑÑ‚Ð°ÐµÐ¼ ÐµÐµ
                    if is_auction:
                        if no_bets:
                            initial_price = tag_auction.contents[1].b.text
                            last_price, last_price_author, url_last_buyer = None, None, None
                        else:
                            initial_price = tag_auction.contents[1].find_all("div")[-1].b.text  # Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ°
                            tag_last_bet = \
                                tag_auction.contents[1].find_all("div", {"style": re.compile("margin-bottom")})[
                                    -1].next_sibling
                            # Ð”Ð¾ÑÑ‚Ð°ÐµÐ¼ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾ ÑÐ´ÐµÐ»Ð°Ð²ÑˆÐµÐ³Ð¾ ÑÑ‚Ð°Ð²ÐºÑƒ
                            if "ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒÐ½Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ" in tag_last_bet.text:
                                tag_last_bet = tag_last_bet.next_sibling
                            last_price = tag_last_bet.b.text
                            last_price_author = tag_last_bet.a.text
                            url_last_buyer = self.MAIN_URL + tag_last_bet.a["href"]
                    else:
                        initial_price, last_price, last_price_author, url_last_buyer = None, None, None, None

                    lot_status = is_closed * "Ð—Ð°ÐºÑ€Ñ‹Ñ‚" + (not is_closed) * "ÐžÑ‚ÐºÑ€Ñ‹Ñ‚"

                    tag_seller = soup.find("div", "head_bg-l clearer").find_all("a", class_="")[1]
                    seller_url = self.MAIN_URL + tag_seller["href"]
                    seller_nickname = tag_seller.text

                    seller_location = soup.find("div", {"style": re.compile("margin-top: 30px")}).div.div.contents[
                        -1].split(",")
                    if len(seller_location) == 3:
                        seller_location_country = seller_location[0]
                        seller_location_district = seller_location[1][1:]
                        seller_location_city = seller_location[2][1:]
                    elif len(seller_location) == 2:
                        seller_location_country = seller_location[0]
                        seller_location_district = None
                        seller_location_city = seller_location[1][1:]
                    elif len(seller_location) == 1:
                        seller_location_country = seller_location[0]
                        seller_location_district, seller_location_city = None, None

                    tag_album = soup.find_all("div", class_="album_item")
                    if tag_album != [] and tag_album[-1].h3 != None and tag_album[-1].h3.a != None:
                        collection = tag_album[-1].h3.a.text
                        url_collection = self.MAIN_URL + tag_album[-1].h3.a["href"]
                        if "/cards/" not in url_collection:
                            collection, url_collection = None, None
                    else:
                        collection, url_collection = None, None

                    # Ð”Ð¾ÑÑ‚Ð°ÐµÐ¼ Ð´Ð°Ñ‚Ñ‹ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð¸Ñ Ð¸ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ñ Ð»Ð¾Ñ‚Ð°
                    tag_time = soup.find_all("div", {"style": re.compile("padding-top: 5px")})
                    date_start_txt = tag_time[0].text
                    date_start = date_start_txt.split("\xa0")
                    date_start[1] = self.MONTH_TO_NUM[date_start[1]]
                    if len(date_start) == 3:
                        date_start.insert(2, str(datetime.datetime.now().year))
                    date_start_day = date_start[0]
                    date_start_month = date_start[1]
                    date_start_year = date_start[2]
                    date_start_time = date_start[3]

                    date_end_txt = tag_time[1].text[1:-8]
                    date_end = date_end_txt.split("\xa0")
                    date_end[1] = self.MONTH_TO_NUM[date_end[1]]
                    if len(date_end) == 3:
                        date_end.insert(2, str(datetime.datetime.now().year))
                    date_end_day = date_end[0]
                    date_end_month = date_end[1]
                    date_end_year = date_end[2]
                    date_end_time = date_end[3]

                    dct = {"title": title, "url": url, "subject": subject, "theme": theme, "lot_type": lot_type,
                           "status": lot_status, "is_bet_made": is_bet_made, "collection": collection,
                           "url_collection": url_collection, "date_start_day": date_start_day,
                           "date_start_month": date_start_month, "date_start_year": date_start_year,
                           "date_start_time": date_start_time, "seller_nickname": seller_nickname,
                           "seller_url": seller_url, "seller_location_city": seller_location_city,
                           "seller_location_district": seller_location_district,
                           "seller_location_country": seller_location_country, "initial_price": initial_price,
                           "last_price": last_price, "last_price_author": last_price_author,
                           "url_last_buyer": url_last_buyer, "date_end_day": date_end_day,
                           "date_end_month": date_end_month, "date_end_year": date_end_year,
                           "date_end_time": date_end_time}
                    df = df.append(dct, ignore_index=True)
                    collection_upper = None if collection == None else collection.upper()
                    df_upper = df_upper.append({"title": title.upper(), "collection": collection_upper},
                                               ignore_index=True)

                    self.df = self.df.append(dct, ignore_index=True)
                    self.df_upper = self.df_upper.append({"title": title.upper(), "collection": collection_upper},
                                                         ignore_index=True)

                    if not json_written and not is_closed:
                        json_written = True
                        self.info["first_open_lot_csv_id"] = passed_pages + self.info["lots_amount"]
                        self.info["first_open_lot_url_id"] = i

                    passed_pages += 1

                    if passed_pages % self.csv_batch == 0:
                        df.to_csv(self.csv_path, sep=";", mode="a", header=False, index=False)
                        df = pd.DataFrame(columns=self.COL_NAMES)
                        df_upper.to_csv(self.upper_csv_path, sep=";", mode="a", header=False, index=False)
                        df_upper = pd.DataFrame(columns=["title", "collection"])

            except Exception:
                self.info["unparsed_pages"].append(url)

        self.info["lots_amount"] += passed_pages

        df.to_csv(self.csv_path, sep=";", mode="a", header=False, index=False)
        df_upper.to_csv(self.upper_csv_path, sep=";", mode="a", header=False, index=False)

        with open(self.json_path, "w") as f:
            json.dump(self.info, f)

    # Ð¢.Ðº. ÐºÐ°ÐºÐ¸Ðµ-Ñ‚Ð¾ Ð»Ð¾Ñ‚Ñ‹ Ð¼Ð¾Ð³Ð»Ð¸ Ð·Ð°ÐºÑ€Ñ‹Ñ‚ÑŒÑÑ, Ð½Ð°Ð´Ð¾ Ð¾Ð±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ð·Ð°Ð¿Ð¸ÑÐ¸
    def __update_downloaded(self, chat_id=None):
        json_updated = False
        # ÐŸÐ¾ÑÐ»Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð±Ð°Ð·Ñ‹, Ð¼Ñ‹ Ð·Ð°Ð¿Ð¾Ð¼Ð½Ð¸Ð»Ð¸ id Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð¾Ð³Ð¾ Ð»Ð¾Ñ‚Ð°. ÐžÐ±Ð½Ð¾Ð²Ð»ÑÑ‚ÑŒ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð¸Ð¼ÐµÐµÑ‚ ÑÐ¼Ñ‹ÑÐ»
        # Ð½Ð°Ñ‡Ð¸Ð½Ð°Ñ Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð»Ð¾Ñ‚Ð° Ð¸ Ð´Ð¾ ÐºÐ¾Ð½Ñ†Ð°, Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ Ð²ÑÐµ Ð»Ð¾Ñ‚Ñ‹ Ð´Ð¾ Ð½ÐµÐ³Ð¾ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ñ‹ Ð¸ ÑÐ²Ð¾ÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ ÑƒÐ¶Ðµ Ð½Ðµ Ð¿Ð¾Ð¼ÐµÐ½ÑÑŽÑ‚
        first, last = self.info.get("first_open_lot_csv_id", len(self.df)), len(self.df)
        rng = tqdm(range(first, last)) if chat_id == None else tq(range(first, last), token=self.token, chat_id=chat_id)

        for i in rng:
            # Ð•ÑÐ»Ð¸ Ð»Ð¾Ñ‚ Ð·Ð°ÐºÑ€Ñ‹Ñ‚, Ñ‚Ð¾ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÑÐµÐ±Ðµ ÑƒÐ¶Ðµ Ð½Ðµ Ð¿Ð¾Ð¼ÐµÐ½ÑÐµÑ‚, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼
            if self.df.iloc[i]["status"] == "ÐžÑ‚ÐºÑ€Ñ‹Ñ‚":
                try:
                    url = self.df.iloc[i]["url"]
                    response = requests.get(url)
                    soup = BeautifulSoup(response.content, "html.parser")

                    if response.status_code != 200:
                        self.df.loc[i, "status"] = "Ð£Ð´Ð°Ð»ÐµÐ½"
                        continue

                    # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ status
                    tag_closed = soup.find("div", id=re.compile("auction_bid_countdown"))
                    is_closed = "Ð”Ð°Ñ‚Ð° Ð¸ Ð²Ñ€ÐµÐ¼Ñ Ð¾ÐºÐ¾Ð½Ñ‡Ð°Ð½Ð¸Ñ" in tag_closed.text
                    lot_status = is_closed * "Ð—Ð°ÐºÑ€Ñ‹Ñ‚" + (not is_closed) * "ÐžÑ‚ÐºÑ€Ñ‹Ñ‚"
                    self.df.loc[i, "status"] = lot_status

                    # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¿Ñ€Ð¾ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ñ‹Ð¹ Ð»Ð¾Ñ‚ Ð² json
                    if not json_updated and not is_closed:
                        json_updated = True
                        self.info["first_open_lot_csv_id"] = i
                        self.info["first_open_lot_url_id"] = int(url[39:-1])

                    is_bet_made = self.df.iloc[i]["is_bet_made"]
                    tag_auction = soup.find("div", {"style": re.compile("float: left; width: 50%")})
                    if not is_bet_made and self.df.iloc[i]["lot_type"] != "ÐžÐ±ÑŠÑÐ²Ð»ÐµÐ½Ð¸Ðµ":
                        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ initial_price Ð¸ is_bet_made
                        is_bet_made = "ÐÐ°Ñ‡Ð°Ð»ÑŒÐ½Ð°Ñ ÑÑ‚Ð°Ð²ÐºÐ°" not in tag_auction.text

                    # Ð’ is_bet_made Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ

                    # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð²ÑÑŽ Ð¸Ð½Ñ„Ñƒ Ð¿Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ¹ ÑÑ‚Ð°Ð²ÐºÐµ
                    # Ð•ÑÐ»Ð¸ ÑÑ‚Ð°Ð²ÐºÐ° Ð²ÑÐµ-Ñ‚Ð°ÐºÐ¸ Ð½Ðµ ÑÐ´ÐµÐ»Ð°Ð½Ð°, Ñ‚Ð¾ Ð¸Ð½Ñ„Ð° Ð½Ðµ Ð¼ÐµÐ½ÑÐµÑ‚ÑÑ
                    if is_bet_made:
                        if not self.df.iloc[i]["is_bet_made"]:
                            initial_price = tag_auction.contents[1].find_all("div")[-1].b.text
                            self.df.loc[i, "initial_price"] = initial_price

                        tag_last_bet = tag_auction.contents[1].find_all("div", {"style": re.compile("margin-bottom")})[
                            -1].next_sibling
                        if "ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒÐ½Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ" in tag_last_bet.text:
                            tag_last_bet = tag_last_bet.next_sibling

                        last_price = tag_last_bet.b.text
                        last_price_author = tag_last_bet.a.text
                        url_last_buyer = self.MAIN_URL + tag_last_bet.a["href"]
                        self.df.loc[i, "last_price"] = last_price
                        self.df.loc[i, "last_price_author"] = last_price_author
                        self.df.loc[i, "url_last_buyer"] = url_last_buyer

                except Exception:
                    pass

        try:
            self.df.to_csv(self.csv_path, sep=";", header=self.COL_NAMES, index=False)
        except Exception:
            self.df.to_csv(self.csv_path[:-4] + "_retry.csv", sep=";", header=self.COL_NAMES, index=False)
            if os.path.isfile(self.csv_path):
                os.remove(self.csv_path)

        return json_updated

    # ÐŸÐ¾Ð´Ð³Ñ€ÑƒÐ·ÐºÐ° Ð•Ð©Ð• ÐÐ• Ð·Ð°Ð¿Ð¸ÑÐ°Ð½Ð½Ñ‹Ñ… Ð»Ð¾Ñ‚Ð¾Ð²
    def __download_new(self, json_updated, chat_id=None):

        now = datetime.datetime.now()
        self.info["last_lot_parse_date"] = "{}:{} {}.{}.{}".format(now.hour, now.minute, now.day, now.month, now.year)

        # Ð£Ð·Ð½Ð°ÐµÐ¼, ÐºÐ°ÐºÐ¾Ð¹ Ð½Ð¾Ð¼ÐµÑ€ Ñƒ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾ Ð½Ð° Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð»Ð¾Ñ‚Ð°
        last_lot_url_id = max(self.last_lot_url_id_now(),
                              self.info["last_lot_url_id"])  # Ð½Ð° ÑÐ»ÑƒÑ‡Ð°Ð¹, ÐµÑÐ»Ð¸ Ð½Ðµ ÑÐ¼Ð¾Ð¶ÐµÑ‚ Ð²Ñ‹Ð¿Ð°Ñ€ÑÐ¸Ñ‚ÑŒ url Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾ Ð»Ð¾Ñ‚Ð°

        self.__parse_to_csv(self.info["last_lot_url_id"] + 1, last_lot_url_id, json_updated, chat_id)
        lots_updated = last_lot_url_id - self.info["last_lot_url_id"]

        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¿Ñ€Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ Ð»Ð¾Ñ‚ Ð² json
        self.info["last_lot_url_id"] = last_lot_url_id
        with open(self.json_path, "w") as f:
            json.dump(self.info, f)

        return (
            self.info["last_lot_parse_date"], self.MAIN_URL + "/auction/post{}/".format(last_lot_url_id), lots_updated)

    def update(self, chat_id=None):
        json_updated = self.__update_downloaded(chat_id)
        return self.__download_new(json_updated, chat_id)

    # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ

    # ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð² Ð¸Ð· Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
    def __to_filters(self, text):
        try:
            words = text.split(" ")
            if not (words[0] == "&" or words[0] == "|"):
                msg = "ÐœÐµÑ‚ÐºÐ° Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ & Ð¸Ð»Ð¸ |, Ð² ÑÐ°Ð¼Ð¾Ð¼ Ð½Ð°Ñ‡Ð°Ð»Ðµ (Ð¿ÐµÑ€ÐµÐ´ Ð½ÐµÐ¹ Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ð°). "
                msg += "ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð½Ð°Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ"
                return (False, msg)
            curr_filter = {"operation": words[0]}  # ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ€Ð°ÑÐ¿Ð°Ñ€ÑÐµÐ½Ð½Ñ‹Ñ… Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²
            for col_ in words[1:]:
                col = col_.upper()
                if "Ð¡Ð¢ÐÐ’Ðš" in col:
                    curr_filter["is_bet_made"] = bool(int(col[-1]))
                elif "Ð¡Ð¢ÐÐ¢Ð£Ð¡Ð›" in col:
                    curr_filter["status"] = (self.DECODE_STATUS[col[-1]], col[0] != "!")
                elif "Ð¢Ð˜ÐŸ" in col:
                    curr_filter["lot_type"] = (self.DECODE_LOT_TYPE[col[-1]], col[0] != "!")
                elif "ÐŸÐ Ð•Ð”Ðœ" in col:
                    curr_filter["subject"] = (self.DECODE_SBJ[col[-1]], col[0] != "!")
                elif "ÐšÐÐ¢Ð•Ð“" in col:
                    curr_filter["theme"] = (self.DECODE_THEME[col[-2:]], col[0] != "!")
                elif "Ð—ÐÐ“ÐžÐ›" in col:
                    curr_filter["title"] = (col.split("=")[1].split("+"), col[0] != "!")
                elif "ÐšÐžÐ›Ð›Ð•Ðš" in col:
                    curr_filter["collection"] = (col.split("=")[1].split("+"), col[0] != "!")
                elif "ÐŸÐ ÐžÐ”ÐÐ’Ð•" in col:
                    curr_filter["seller_nickname"] = (col_.split("=")[1], col[0] != "!")
                elif "ÐÐ•Ð ÐÐÐ¬Ð¨" in col or "ÐÐ•Ð ÐÐÐ•Ð•" in col:
                    curr_filter["not_earlier"] = col.split("=")[1]
                elif "ÐÐ•ÐŸÐžÐ—Ð”ÐÐ•" in col or "ÐÐ•ÐŸÐžÐ—Ð–" in col:
                    curr_filter["not_later"] = col.split("=")[1]
                elif "Ð¡ÐžÐ Ð¢Ð˜Ð ÐžÐ’ÐÐ¢Ð¬" in col:
                    curr_filter["sort_by"] = self.DECODE_SORT_BY[col.split("=")[1]]
                elif "ÐœÐžÐ˜Ð¤Ð˜Ð›Ð¬Ð¢Ð Ð«" in col:
                    curr_filter["my_filters"] = col_.split("=")[1].split("+")
                elif "ÐŸÐžÐšÐ£ÐŸÐÐ¢" in col:
                    curr_filter["last_price_author"] = (col_.split("=")[1], col[0] != "!")
                elif col != "":
                    msg = "ÐÐµ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð½ÑÑ‚ÑŒ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ " + col_ + ". ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ð¼ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ /howfilter"
                    return (False, msg)

            return (True, curr_filter)

        except Exception:
            msg = "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ñ€Ð°ÑÐ¿Ð°Ñ€ÑÐ¸Ñ‚ÑŒ Ð·Ð°Ð¿Ñ€Ð¾Ñ. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ð¼ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ /howfilter"
            return (False, msg)

    @staticmethod
    def index_to_select_from(df, operation):
        return set(df.index) if operation == "&" else set()

    @staticmethod
    def join(s1, s2, operation):
        if operation == "&":
            s1 &= s2
        else:
            s1 |= s2

    # Ð¡Ð¼Ð¾Ñ‚Ñ€Ð¸Ð¼, ÐºÐ°ÐºÐ¸Ðµ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹ ÑÐ¾Ð·Ð´Ð°Ð» Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ñ id=user_id
    def __read_user_filters(self, user_id):
        user_filters_path = "{}/user_{}_filters.json".format(self.dir_path + "/users_filters", user_id)
        if os.path.isfile(user_filters_path):
            with open(user_filters_path, "r") as f:
                user_filters = json.load(f)
            return user_filters
        return {}

    # ÐŸÐ¾ Ñ€Ð°ÑÐ¿Ð°Ñ€ÑÐµÐ½Ð½Ð¾Ð¼Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ Ð±Ð°Ð·Ñƒ
    def __select_index(self, filter_dct, df, user_filters):
        from_index = df.index
        operation = filter_dct["operation"]
        selected_inds = self.index_to_select_from(df, operation)

        # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ "Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ðµ" Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹, Ñ‚.Ðµ. Ð½Ðµ Ñ‚Ðµ, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÑÐ¾Ð·Ð´Ð°Ð» Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ
        for col in filter_dct:
            if col == "operation" or col == "sort_by" or col == "my_filters":
                continue

            elif col == "subject" or col == "theme" or col == "lot_type" or col == "status":
                local_inds = set(df[(df[col] == filter_dct[col][0]) == filter_dct[col][1]].index)

            elif col == "title" or col == "collection":
                upper_df = self.df_upper.loc[list(from_index)]
                for word in filter_dct[col][0]:
                    upper_df = upper_df[upper_df[col].str.contains(word) == True]
                if filter_dct[col][1]:
                    local_inds = set(df.index) & set(upper_df.index)
                else:
                    local_inds = set(df.index) - set(upper_df.index)

            elif col == "seller_nickname" or col == "last_price_author":
                local_inds = set(df[(df[col] == filter_dct[col][0]) == filter_dct[col][1]].index)

            elif col == "not_earlier" or col == "not_later":
                day_s, month_s, year_s = filter_dct[col].split(".")
                day, month, year = int(day_s), int(month_s), int(year_s)
                df_ = df[:]
                if col == "not_earlier":
                    df_ = df_[df_["date_end_year"] >= year]
                    df_ = df_[df_["date_end_month"] >= month]
                    local_inds = set(df_[df_["date_end_day"] >= day].index)
                if col == "not_later":
                    df_ = df_[df_["date_end_year"] <= year]
                    df_ = df_[df_["date_end_month"] <= month]
                    local_inds = set(df_[df_["date_end_day"] <= day].index)

            else:
                local_inds = set(df[df[col] == filter_dct[col]].index)

            self.join(selected_inds, local_inds, operation)

            if operation == "&":
                df = df.loc[list(selected_inds)]
                from_index = df.index

        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ðµ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹ (ÐµÑÐ»Ð¸ Ð¾Ð½Ð¸ ÐµÑÑ‚ÑŒ Ð² Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ)
        for my_filter in filter_dct.get("my_filters", []):
            if my_filter not in user_filters:
                msg = "Ð—Ð°Ð¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÐ¼Ð¾Ð³Ð¾ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð° " + my_filter + " Ð½ÐµÑ‚ Ð² Ð±Ð°Ð·Ðµ â˜¹ï¸ ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð½Ð°Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ. "
                msg += "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ñ… Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð² /showfilters"
                return False, msg

            success, result = self.__select_index(user_filters[my_filter][0], df[:], user_filters)
            if not success:
                return success, result

            self.join(selected_inds, result, operation)
            if operation == "&":
                df = df.loc[list(selected_inds)]
                from_index = df.index

        return True, selected_inds

    def __select(self, dct, user_id):
        try:
            df = self.df[:]
            if len(dct) == 1 or (len(dct) == 2 and "sort_by" in dct):  # ÐµÑÐ»Ð¸ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¸Ð»Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÑƒ
                pass
            else:
                user_filters = self.__read_user_filters(user_id)
                success, result = self.__select_index(dct, df, user_filters)
                if not success:
                    return success, result
                df = df.loc[list(result)]

            # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ñ‚Ð°ÐºÐ¾Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ
            if "sort_by" in dct and dct["sort_by"] == "index":
                df.sort_index(inplace=True)
            elif "sort_by" in dct:
                df.sort_values(dct["sort_by"], inplace=True, na_position="first")

            return True, df
        except Exception:
            msg = "Ð§Ñ‚Ð¾-Ñ‚Ð¾ Ð¿Ð¾ÑˆÐ»Ð¾ Ð½Ðµ Ñ‚Ð°Ðº. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾ÑÑ‚ÑŒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°. Ð˜ÑÐºÐ¾Ð¼Ñ‹Ðµ Ð¿Ð¾Ð´ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ "
            msg += "ÑÐ¾Ð²Ð¿Ð°Ð´Ð°Ñ‚ÑŒ ÑÐ¾ ÑÐ»ÑƒÐ¶ÐµÐ±Ð½Ñ‹Ð¼Ð¸ ÑÐ»Ð¾Ð²Ð°Ð¼Ð¸ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸. ÐšÐ¾Ð¼Ð°Ð½Ð´Ð° /howfilter Ñ€Ð°ÑÑÐºÐ°Ð¶ÐµÑ‚ Ð¾ ÐµÐµ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ñ…"
            return False, msg

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð·Ð°ÐºÑ€ÐµÐ¿Ð»ÐµÐ½ Ð»Ð¸ Ð·Ð° Ð½Ð°ÑˆÐµÐ¹ Ð±Ð°Ð·Ð¾Ð¹ Ð±Ð¾Ñ‚
    def __check_from_telegram(self, user_id):
        assert self.token != "", "Ð­Ñ‚Ð¾Ñ‚ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð» Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‡ÐµÑ€ÐµÐ· Telegram. Ðš Ð¾Ð±ÑŠÐµÐºÑ‚Ñƒ Ð½Ðµ Ð¿Ñ€Ð¸Ð²ÑÐ·Ð°Ð½ Ð½Ð¸ Ð¾Ð´Ð¸Ð½ Ð±Ð¾Ñ‚"
        msg = "Ð­Ñ‚Ð¾Ñ‚ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð» Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‡ÐµÑ€ÐµÐ· Telegram. Ð˜Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð° Ñ‡Ð°Ñ‚Ð°, Ð² ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð±ÑƒÐ´ÑƒÑ‚ Ð¿Ñ€Ð¸ÑÑ‹Ð»Ð°Ñ‚ÑŒÑÑ "
        msg += "Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹, Ð½ÐµÑ‚ Ð¸Ð»Ð¸ Ð¾Ð½ Ð½ÐµÐ´Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ð¾Ð³Ð¾ Ñ‚Ð¸Ð¿Ð°"
        assert type(user_id) == int, msg

    def filter_(self, text, user_id):
        self.__check_from_telegram(user_id)
        ans = self.__to_filters(text)
        if not ans[0]:  # ÐµÑÐ»Ð¸ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ð»Ð°ÑÑŒ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹
            return ans
        curr_filters = ans[1]
        result = self.__select(curr_filters, user_id)
        return result

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ð¹ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€
    def create_new_filter(self, text, user_id):
        self.__check_from_telegram(user_id)
        try:
            users_filters_dir_path = "{}/users_filters".format(self.dir_path)
            user_filters_path = "{}/user_{}_filters.json".format(users_filters_dir_path, user_id)

            if not os.path.isdir(users_filters_dir_path):
                os.mkdir(users_filters_dir_path)

            if os.path.isfile(user_filters_path):
                with open(user_filters_path, "r") as f:
                    user_filters = json.load(f)
            else:
                user_filters = {}

            words = text.split(" ")
            filter_name = words[0]
            if filter_name in user_filters:
                return "Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ Ñ Ñ‚Ð°ÐºÐ¸Ð¼ Ð¸Ð¼ÐµÐ½ÐµÐ¼ ÑƒÐ¶Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚. ÐžÐ½ Ð·Ð°Ð¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÑ‚\n*" + user_filters[filter_name][1] + "*"

            to_parse = " ".join(words[1:])
            if "ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ" in to_parse:
                return "ÐÐµÐ»ÑŒÐ·Ñ ÑÐ¾Ð·Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ðµ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹ Ñ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ¾Ð¹ ðŸ™…â€â™‚ï¸"

            success, result = self.__to_filters(to_parse)
            if not success:
                return result

            user_filters[filter_name] = (result, to_parse)
            with open(user_filters_path, "w") as f:
                json.dump(user_filters, f)
            return "Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑÐ¾Ð·Ð´Ð°Ð½"

        except Exception:
            msg = "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾ÑÑ‚ÑŒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: Ð¼ÐµÐ¶Ð´Ñƒ /newfilter, Ð¸Ð¼ÐµÐ½ÐµÐ¼ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð° "
            msg += "Ð¸ ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð¼ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸ (& Ð¸Ð»Ð¸ |) Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ñ€Ð¾Ð²Ð½Ð¾ Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¼Ñƒ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñƒ. Ð¢ÐµÐºÑÑ‚ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ Ñ‚Ð°ÐºÐ¶Ðµ "
            msg += "Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚ÐµÐ½, /howfilter Ð¿Ð¾Ð´ÑÐºÐ°Ð¶ÐµÑ‚"
            return msg

    # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ð¹ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€
    def delete_filter(self, filter_name, user_id):
        self.__check_from_telegram(user_id)
        user_filters_path = "{}/user_{}_filters.json".format(self.dir_path + "/users_filters", user_id)
        if os.path.isfile(user_filters_path):
            with open(user_filters_path, "r") as f:
                user_filters = json.load(f)
            if filter_name not in user_filters:
                msg = "Ð¢Ð°ÐºÐ¾Ð¹ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ ÐµÑ‰Ðµ Ð½Ðµ Ð±Ñ‹Ð» ÑÐ¾Ð·Ð´Ð°Ð½ ðŸ˜ Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ð´Ð¾ Ð¸ "
                msg += "Ð¿Ð¾ÑÐ»Ðµ ÐµÐ³Ð¾ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ Ð½ÐµÑ‚ Ð½ÐµÐ·Ð½Ð°Ñ‡Ð°Ñ‰Ð¸Ñ… Ð¿Ñ€Ð¾Ð±ÐµÐ»Ð¾Ð²"
                return msg
            user_filters.pop(filter_name)
            with open(user_filters_path, "w") as f:
                json.dump(user_filters, f)
            return "Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑƒÐ´Ð°Ð»ÐµÐ½ ðŸ‘"
        return "Ð’Ñ‹ ÐµÑ‰Ðµ Ð½Ðµ ÑÐ¾Ð·Ð´Ð°Ð»Ð¸ Ð½Ð¸ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð° ðŸ¤·â€"


if __name__ == "__main__":
    LastStickerStat(sys.argv[1])